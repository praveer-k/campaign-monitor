\documentclass[a4paper,12pt, notitlepage]{article}

\usepackage[margin=0.5in]{geometry}
\usepackage[english]{babel}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{xcolor,colortbl}
\usepackage{multirow}

\definecolor{Gray}{gray}{0.90}

\makeatletter
\newcommand*{\toc}{\@starttoc{toc}}{\let\clearpage\relax}
\newcommand*{\lof}{\@starttoc{lof}}{\let\clearpage\relax}
\newcommand*{\lot}{\@starttoc{lot}}{\let\clearpage\relax}
\makeatother

\geometry{ left=20mm, top=20mm, bottom=20mm }

\begin{document}
\title{Election Campaign Monitor}
\author{Praveer Kumar}
\maketitle
\section*{Table of Contents}
\toc
\section*{List of Figures}
\lof
\section*{List of Tables}
\lot

\section{Introduction}
\rule{\textwidth}{0.5pt}
\par
This report is generated using the dataset extracted from Twitter using the keywords \textbf{XXXX} and, \textbf{XXXX}. It is saved under the name \textbf{XXXX}. This dataset is collected from the country \textbf{XXXX} and potrays the viewpoint of the people as seen on the platform ``Twitter'', strictly between the dates \textbf{XXXX} and \textbf{XXXX}.

\begin{mdframed}[hidealllines=true,backgroundcolor=blue!20]
\textbf{Please Note:} The Report is generated automatically and is intented for an overview of the model only.
\end{mdframed}
\par
In order to analyse the effect of sentiments on the overall decision of the people, each text downloaded from Twitter were analysed for its sentiment using voted classifier. Once these positive/negative sentiments are labled for each text, a further investigation is carried out to analyse the effects of different predictors such as place, device, user etc. on the overall decision of the people using logistic regression.
\par
Each hastag for either of the keywords recieved is counted as "+1 vote". Out of the few models considered the best model is picked using Akaike Information Criteria or AIC. Once the best model is selected, the significane of each variable is calculated. The report is then interpreted for each descriptor used. To cross verify the quality of the model daignostic graphs are also obtained. The steps followed during the process is mentioned in the following sections.

\section{Training}
\rule{\textwidth}{0.5pt}
\par
The accuracy of each classifier after training them with the NLTK corpus for Twitter Senitment Analysis is mentioned in the table \ref{table:1} as follows.

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{ |l|r| } 
\hline \rowcolor{Gray}
Classifier & Accuracy   \\[1ex]
\hline
MultinomialNB & 93.10\%   \\[1ex] 
BernoulliNB & 94.75\%  \\[1ex] 
LogisticRegression & 95.10\% \\[1ex] 
SGDClassifier & 95.10\% \\[1ex] 
SVC & 94.95\% \\[1ex] 
NuSVC & 94.95\% \\[1ex] 
LinearSVC & 94.90\% \\[1ex] 
\hline
\end{tabular}
%-------------------------------------%
\caption{Accuracy of the Classifiers trained for Sentiment Analysis}
\label{table:1}
\end{table}

\section{Cleaning}
\rule{\textwidth}{0.5pt}
\par
In order to clean the data obtained using the Twitter APIs, first the discriptor variables are grouped to see the relationship between various choosen predictor variables according to user, place, tweets, and source as mentioned in the table \ref{table:2} as follows.

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{ |l|l|l|l|l| } 
\hline \rowcolor{Gray}
tweet & place & author & user & source \\[1ex]
\hline
tweet id      & place id    & author id          & user id             & source \\[1ex]
created at    & subdivision & author screen name & name                &        \\[1ex]
lang          & location    &                    & screen name         &        \\[1ex]
retweeted     &             &                    & user created at     &        \\[1ex]
text          &             &                    & description         &        \\[1ex]
links         &             &                    & friends count       &        \\[1ex]
retweet count &             &                    & statuses count      &        \\[1ex]
              &             &                    & followers count     &        \\[1ex]
              &             &                    & favourites count    &        \\[1ex]
              &             &                    & contributors enabled&        \\[1ex]
\hline
\end{tabular}
%-------------------------------------%
\caption{Discriptor variables grouped according to user, place, tweets etc.}
\label{table:2}
\end{table}

\par
Then, they are categorized according to the relevance in the model, as mentioned in the table \ref{table:3} below.

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{ |l|l|l|l|l| } 
\hline \rowcolor{Gray}
numeric	 & 	multifactors & twofactors & timeseries & dropable \\[1ex]
\hline
friends count    & author screen name & user id     & created at          & category \\[1ex]
statuses count   & source           & name      & user created at & contributors enabled\\[1ex]
followers count  & screen name        & description &             & retweeted \\[1ex]
favourites count & subdivision        & place id    &             &        \\[1ex]
retweet count    &                    & location    &             &        \\[1ex]
confidence       &                    & tweet id    &             &        \\[1ex]
                 &                    & lang        &             &        \\[1ex]
                 &                    & links       &             &        \\[1ex]
                 &                    & author id   &             &        \\[1ex]
                 &                    &             &             &        \\[1ex]
\hline
\end{tabular}
%-------------------------------------%
\caption{Discriptor variables grouped according to relevance in the model}
\label{table:3}
\end{table}

\par
It can be seen from the table above that the multifactor predictor need factor reduction. Also, time series column can be used to understand which keyword was spoken at what time. Since, the dropable variables give the same information as few other variables they are dropped from the model. The frequency distribution charts are plotted for each of these variables as mentioned the figure \ref{fig:hist1} below.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Histogram for frequency of tweets}
    \label{fig:hist1}
\end{figure}

\par
From the figure \ref{fig:hist1} it can be seen that the number of unique tweets from the
downloaded set of tweets is XXXX where as the number of tweets that appear to be same are XXXX. It can also be noted that the few of the tweets are retweeted more than the others with the tweet ``XXXX'' being tweeted the most. It appears in the dataset at indexes XXXX from the users XXXX.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Text Comparision - Individual and Re-Tweets}
    \label{fig:vbarplot1}
\end{figure}

\par
The figure \ref{fig:vbarplot1} shows the number of tweets that contains 'RT ' in front of the given text and those that do not contain it. From this frequency plot it can be seen
that the number of individual tweets is XXXX and number of re-tweets is XXXX in count.

\par
The following graphs show the analysis of tweets, according to locations.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Box plot of tweets frequency from various places in XXXX }
    \label{fig:boxplot1}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Frequency distribution tweets in XXXX }
    \label{fig:vbarplot2}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Histogram for tweets Frequency w.r.t places}
    \label{fig:hist2}
\end{figure}

\par
From the figure \ref{fig:boxplot1}, \ref{fig:vbarplot2}, \ref{fig:hist2}, it is clear that people from XXXX tend to tweet more other places and from the boxplot it is clear that the data is XXXX.

\par
The following graphs show the analysis of tweets according to the sources or the devices used for tweeting. It is interesting to see which voters tend to use which kind of device.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Box plot of tweets frequency from various sources}
    \label{fig:boxplot2}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Frequency distribution sources of tweets}
    \label{fig:vbarplot3}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Histogram for tweets Frequency w.r.t sources}
    \label{fig:hist3}
\end{figure}

\par
The figure \ref{fig:boxplot2}, \ref{fig:vbarplot3} and \ref{fig:hist3} shows that the twitter users tweet mainly using XXXX device more than any other. From the boxplot it is clear that the data is XXXX.

\par
The following graphs show the analysis of tweets w.r.t. the screen names of the users. These graphs help in understanding the tweeting frequency of each user.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Box plot of users frequencies of tweets}
    \label{fig:boxplot3}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Frequency distribution user's tweets}
    \label{fig:vbarplot4}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Histogram for users tweeting Frequency}
    \label{fig:hist4}
\end{figure}

\par
The figure \ref{fig:boxplot3}, \ref{fig:vbarplot4} and, \ref{fig:hist4} shows that the twitter users XXXX tend to tweet more about the keywords XXXX and, XXXX than any other person on twitter from the sample. From the boxplot it is clear that the data is XXXX.

\par
The following graph show the time series analysis of tweets w.r.t. keywords been talked about, over the given period of time.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Conversation on XXXX and XXXX over the period of time}
    \label{fig:timeseries1}
\end{figure}

\section{Modelling}
\rule{\textwidth}{0.5pt}
\par
Various selection process and interaction terms are used in order to identify the statistically significant predictors in the model. After reducing the factor levels and creating dummy variables we apply the logit function on our model and check for significance level of predictor in each model. Akaike Information Criteria for the models are mentioned in the table \ref{table:4} as follows.

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{ |l|r| } 
\hline \rowcolor{Gray}
Model & AIC   \\
\hline
Model 1 & 93.10  \\ 
Model 2 & 94.75  \\ 
Model 3 & 95.10  \\ 
Model 4 & 95.10  \\ 
\hline
\end{tabular}
%-------------------------------------%
\caption{AIC	values	obtained	for	each	model}
\label{table:4}
\end{table}

\par
So, the best model among the selected model is mentioned as follows.

\begin{mdframed}[hidealllines=true,backgroundcolor=gray!20]
formula 
\end{mdframed}

\par
After careful few iterations, the following logit model is fitted. The result summary obtained from this model is mentioned in the table \ref{table:5} as follows.

\begin{mdframed}[hidealllines=true,backgroundcolor=gray!20]
Model
\end{mdframed}

\par
Since the log likelyhood ratio p-value (LLR p-value) is euqal to XXXX which is XXXX 0.05 therefore, the null hypothesis is XXXX and it is concluded that the votes are XXXXX of the discriptor variables. % So, we do not proceed with further diagnostics.
\par
The confidence interval and the odds ratio is mentioned in the table \ref{table:5} as follows:

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{ |l|r|r|r| } 
\hline \rowcolor{Gray}
Predictor & Lower CI & Upper CI & Odds Ratio   \\
\hline
p1 & 93.10 & 93.10 & 93.10 \\ 
p2 & 94.75 & 93.10 & 93.10 \\ 
p3 & 95.10 & 93.10 & 93.10 \\ 
p4 & 95.10 & 93.10 & 93.10 \\ 
\hline
\end{tabular}
%-------------------------------------%
\caption{Confidence Interval and Odds Ratio for the selected model}
\label{table:5}
\end{table}

So, it can be seen from the model above that the discriptor variables XXXX are statistically significant where as, the variables XXXX are not significant.

\section{Interpretation}
\rule{\textwidth}{0.5pt}
\par
According to the given model, following can be said about the given model:

\begin{itemize}
  \item The odds of people voting for XXXX is XXXX-XXXX likely to occur, if there is no one voting/tweeting.
  \item For 1 unit increase in XXXX the odds of people voting for XXXX is likely to XXXX by XXXX.
  \item The odds of people voting for XXXX does not change w.r.t XXXX.
  \item The odds of people voting for XXXX-XXXX likely when the XXXX is XXXX as compared to XXXX XXXX-XXXX.
\end{itemize}

\section{Diagnostics}
\rule{\textwidth}{0.5pt}
\par
Dependent variable (y), predicted values of y(ypred), error terms (e), hat values (h), pearson's residual values (rpear), deviance residual values (rdev) and, cook's distance values (D) are clubed together for closer investigation. The table \ref{table:6} shows a small portion of the data frame generated by grouping these variables into one dataframe.

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{ |l|r|r|r|r|r|r| } 
\hline \rowcolor{Gray}
h & y & rdev & rpear & e & ypred & D\\
\hline
93.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 \\ 
94.75 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 \\ 
95.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 \\ 
95.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 & 93.10 \\ 
\hline
\end{tabular}
%-------------------------------------%
\caption{Diagnostics summary for sample dataset}
\label{table:6}
\end{table}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Index plot of pearson's residual}
    \label{fig:rpear1}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Index plot of deviance residual}
    \label{fig:rdev1}
\end{figure}

Since, the pearson's residual and deviance residual is randomly scattered, having bands of rectangular cloud. So, the systematic component of the model is correct. 

The following graphs show the cases of high leverage and cases of high influence.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Plot for identifying cases of high leverage}
    \label{fig:highleverage1}
\end{figure}

The figure \ref{fig:highleverage1} shows the cases of high leverage. The values above the cut off XXXX line marked in red are the cases of high leverage. In this case, we have XXXX cases of high leverage. They are indexed as XXXX in the dataset.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Fig1.png}
    \caption{Plot for identifying cases of high influence}
    \label{fig:highInfluence1}
\end{figure}

The figure \ref{fig:highInfluence1} shows the cases of high influence. In this case, we have XXXX cases of high influence and they are indexed as XXXX in the dataset.

\section{Accuracy}
\rule{\textwidth}{0.5pt}
\par
The accuracy of the model is obtained by considering the predicted values above 0.5 as XXXX while, values below or equal to 0.5 is considered as XXXX. A confusion matrix is plotted in order to obtain the overall accuracy of the model. The table \ref{table:7} shows the confusion matrix.

\begin{table}[!htbp]
\centering
%-------------------------------------%
\begin{tabular}{cc|c|c|c|} \cline{3-5}
 & & \multicolumn{2}{c|}{\cellcolor{Gray!50}Predicted} & \cellcolor{Gray!50}Total \\[1ex] \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{ \cellcolor{Gray!50}Actual}} & \#XXXX & 6 & 230 & 35 \\[1ex]
\multicolumn{1}{|c|}{\cellcolor{Gray!50} } & \#XXXX & 6 & 230 & 35 \\[1ex] \hline
\multicolumn{1}{c|}{} & \cellcolor{Gray!50} Total & 5 & 195 & 25 \\[1ex] \cline{2-5}
\end{tabular}
%-------------------------------------%
\caption{Confusion Matrix for the Model}
\label{table:7}
\end{table}

So, the model is accurately able to identify XXXX\% of the results for XXXX and XXXX\% for XXXX. Also, the overall accuracy of the model is XXXX\%. So, we can say that the model performs XXXX in predicting the accuracy of XXXX and also does XXXX while predicting the accuracy of XXXX. Consequently, it can be said that XXXX\% of the people are sure to vote for XXXX and, XXXX\% of the people are sure to vote for XXXX.

\end{document}

